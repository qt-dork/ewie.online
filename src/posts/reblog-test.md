---
title: Test reblog document
description: Testing reblog data
date: 2026-02-05T17:12:27Z
tags:
 - testing
 - reblogs
---

{
  author:
    username: "ewie"
    displayName: "Evie Finch"
    avatar: "https://cdn.ewie.online/ewie-pfp.png"
  date: 2026-02-05T17:12:27Z
}
{ metadataTwo: value }
::: reblog
regular markdown post content in here
:::

{ 
  url: "https://anthonymoser.github.io/writing/ai/haterdom/2025/08/26/i-am-an-ai-hater.html"
  title: "I Am An AI Hater"
  date: "2025-08-26T17:14:27+00:00"
  author:
    displayName: "moser's frame shop"
}
::: reblog
I am an AI hater. This is considered rude, but I do not care, because I am a hater.

To speak politely about AI, you put disclaimers before criticism: of course I’m not against it entirely; perhaps in a few years when; maybe for other purposes, but. You are supposed to debate how and when it should be used. You are supposed to take for granted that it must be useful somewhere, to someone, for something, eventually. People who are rich and smart and respected are saying so, and it would be arrogant to disagree with such people.

But I am a hater, which is a kind of integrity. It means I am willing to disagree with anyone, even if it is rude. “But I only use it to–” “Actually if you just—” “The new models–” “I was making fun–” Stop. You’re embarrassing yourself. I am embarrassed for you.

Critics have already written thoroughly about the [environmental](https://www.teenvogue.com/story/chatgpt-is-everywhere-environmental-costs-oped) [harms](https://www.bbc.com/news/articles/cy8gy7lv448o), the [reinforcement](https://apnews.com/article/ai-artificial-intelligence-health-business-90020cdf5fa16c79ca2e5b6c4c9bbb14) of [bias](https://www.noemamag.com/the-exploited-labor-behind-artificial-intelligence/) and generation of [racist output](https://www.npr.org/2025/07/09/nx-s1-5462609/grok-elon-musk-antisemitic-racist-content), the [cognitive harms](https://www.bloomberg.com/news/articles/2025-08-12/ai-eroded-doctors-ability-to-spot-cancer-within-months-in-study?embedded-checkout=true) and [AI supported suicides](https://www.nytimes.com/2025/08/26/technology/chatgpt-openai-suicide.html), the problems with [consent](https://www.404media.co/deepfake-harassment-ohio-undress-clothoff-nudify-apps/) and [copyright](https://jskfellows.stanford.edu/theft-is-not-fair-use-474e11f0d063), the way AI tech companies further the [patterns of empire](https://karendhao.com/), how [it’s a con](https://thecon.ai/) that enables [fraud](https://voiceofsandiego.org/2025/04/14/as-bot-students-continue-to-flood-in-community-colleges-struggle-to-respond/) and [disinformation](https://www.technologyreview.com/2023/10/04/1080801/generative-ai-boosting-disinformation-and-propaganda-freedom-house/) and [harassment](https://www.reuters.com/world/us/fbi-says-artificial-intelligence-being-used-sextortion-harassment-2023-06-07/) and [surveillance](https://www.aclu.org/news/privacy-technology/machine-surveillance-is-being-super-charged-by-large-ai-models), the [exploitation of workers](https://www.wired.com/story/millions-of-workers-are-training-ai-models-for-pennies/), as an [excuse to fire workers](https://www.theverge.com/news/688679/amazon-ceo-andy-jassy-ai-efficiency) and de-skill work, how they [don’t actually reason](https://machinelearning.apple.com/research/illusion-of-thinking) and probability and association are [inadequate to the goal of intelligence](https://thegradient.pub/machine-learning-wont-solve-the-natural-language-understanding-challenge/), how people think it makes them faster when it [makes them slower](https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/), how it is inherently mediocre and fundamentally conservative, how it is at its core a [fascist technology](https://newsocialist.org.uk/transmissions/ai-the-new-aesthetics-of-fascism/) rooted in the [ideology of supremacy](https://aworkinglibrary.com/writing/toolmen), defined not by its technical features but [by its political ones](https://ali-alkhatib.com/blog/defining-ai).

But I am more than a critic: I am a hater. I am not here to make a careful comprehensive argument, because people have already done that. If you’re pushing slop or eating it, you wouldn’t read it anyway. You’d ask a bot for a summary and forget what it told you, then proceed with your day, unchanged by words you did not read and ideas you did not consider.

I am here to be rude, because this is a rude technology, and it deserves a rude response. Miyazaki said, “ [I strongly feel that this is an insult to life itself.](https://www.yahoo.com/news/insult-life-itself-studio-ghiblis-193724631.html)” Scam Altman said we can [surround the solar system with a Dyson Sphere](https://fight.fudgie.org/search/show/tpw/episode/20250723_Wed#line3691) to hold data centers. Miyazaki is right, and Altman is wrong. Miyazaki tells stories that blend the ordinary and the fantastic in ways people find deeply meaningful. Altman tells lies for money.

And I’m glad they’re lies. Because the makers of AI aren’t damned by their failures, they’re damned by their goals. They want to build a genie to grant them wishes, and their wish is that nobody ever has to make art again. They want to create a new kind of mind, so they can force it into mindless servitude. Their dream is to invent new forms of life to enslave.

And to what end? In a kind of nihilistic symmetry, their dream of the perfect slave machine drains the life of those who use it as well as those who turn the gears. What is life but what we choose, who we know, what we experience? Incoherent empty men want to sell me the chance to stop reading and writing and thinking, to stop caring for my kids or talking to my parents, to stop choosing what I do or knowing why I do it. Blissful ignorance and total isolation, warm in the womb of the algorithm, nourished by hungry machines.

And even as it consumes those who use it, even as the scammers become their own marks, even as it is sustained by exploited workers slotted in as human filters for algorithmic abuse – some people want to have a little, as a treat. As a joke. Just to make fun of it, just for the busywork, because it’s good enough, right? You understand.

I do understand: you want permission. There’s a machine in the corner wrapped in human skin that makes things out of shit and blood to look like whatever you want (as long as you don’t look too closely). You gave one to your teacher and they didn’t notice. Your boss told you to use it after they laid off half the team and it was fine. You fed one to your kids and they liked it. You want to know you can use it sometimes without me thinking less of you. You don’t need me to believe it’s useful, you just want me to be polite about it.

But I am a hater, and I will not be polite. The machine is disgusting and we should break it. The people who build it are vapid shit-eating cannibals glorifying ignorance. I strongly feel that this is an insult to life itself.

I became a hater by doing precisely those things AI cannot do: reading and understanding human language; thinking and reasoning about ideas; considering the meaning of my words and their context; loving people, making art, living in my body with its flaws and feelings and life. AI cannot be a hater, because AI does not feel, or know, or care. Only humans can be haters. I celebrate my humanity.
:::



Cases that should fail:

stuff :::

yeah

:::



test

```
testing

:::
test
:::

testing
```

test
